{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/YaminiMuralidharen/MachineLearningexercises/blob/master/LogisticRegression.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ekn0xfMfHQL8",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "61aa4849-9f97-45e0-96b7-4f2c56680a25"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20358f26-9620-4994-8b88-75f8ea1f655c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-20358f26-9620-4994-8b88-75f8ea1f655c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ChurnData.csv to ChurnData.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OQbxRRP7Hzja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "256d4075-1cd2-44d9-e2eb-1c5b2965311e"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "churn_df = pd.read_csv(\"ChurnData.csv\")\n",
        "churn_df.head(10)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>income</th>\n",
              "      <th>ed</th>\n",
              "      <th>employ</th>\n",
              "      <th>equip</th>\n",
              "      <th>callcard</th>\n",
              "      <th>wireless</th>\n",
              "      <th>longmon</th>\n",
              "      <th>...</th>\n",
              "      <th>pager</th>\n",
              "      <th>internet</th>\n",
              "      <th>callwait</th>\n",
              "      <th>confer</th>\n",
              "      <th>ebill</th>\n",
              "      <th>loglong</th>\n",
              "      <th>logtoll</th>\n",
              "      <th>lninc</th>\n",
              "      <th>custcat</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.40</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.482</td>\n",
              "      <td>3.033</td>\n",
              "      <td>4.913</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.246</td>\n",
              "      <td>3.240</td>\n",
              "      <td>3.497</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.841</td>\n",
              "      <td>3.240</td>\n",
              "      <td>3.401</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.800</td>\n",
              "      <td>3.807</td>\n",
              "      <td>4.331</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.960</td>\n",
              "      <td>3.091</td>\n",
              "      <td>4.382</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>68.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.030</td>\n",
              "      <td>3.240</td>\n",
              "      <td>4.787</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>42.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.110</td>\n",
              "      <td>3.157</td>\n",
              "      <td>3.611</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.065</td>\n",
              "      <td>3.240</td>\n",
              "      <td>2.833</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.872</td>\n",
              "      <td>3.314</td>\n",
              "      <td>4.942</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>49.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.85</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.553</td>\n",
              "      <td>3.248</td>\n",
              "      <td>4.143</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
              "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
              "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
              "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
              "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
              "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
              "5    68.0  52.0     17.0   120.0  1.0    24.0    0.0       1.0       0.0   \n",
              "6    42.0  40.0      7.0    37.0  2.0     8.0    1.0       1.0       1.0   \n",
              "7     9.0  21.0      1.0    17.0  2.0     2.0    0.0       0.0       0.0   \n",
              "8    35.0  50.0     26.0   140.0  2.0    21.0    0.0       1.0       0.0   \n",
              "9    49.0  51.0     27.0    63.0  4.0    19.0    0.0       1.0       0.0   \n",
              "\n",
              "   longmon  ...    pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
              "0     4.40  ...      1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
              "1     9.45  ...      0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
              "2     6.30  ...      0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
              "3     6.05  ...      1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
              "4     7.10  ...      0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
              "5    20.70  ...      0.0       0.0       0.0     0.0    0.0    3.030    3.240   \n",
              "6     8.25  ...      0.0       1.0       1.0     1.0    1.0    2.110    3.157   \n",
              "7     2.90  ...      0.0       0.0       0.0     0.0    0.0    1.065    3.240   \n",
              "8     6.50  ...      0.0       0.0       1.0     1.0    0.0    1.872    3.314   \n",
              "9    12.85  ...      0.0       1.0       1.0     0.0    1.0    2.553    3.248   \n",
              "\n",
              "   lninc  custcat  churn  \n",
              "0  4.913      4.0    1.0  \n",
              "1  3.497      1.0    1.0  \n",
              "2  3.401      3.0    0.0  \n",
              "3  4.331      4.0    0.0  \n",
              "4  4.382      3.0    0.0  \n",
              "5  4.787      1.0    0.0  \n",
              "6  3.611      4.0    0.0  \n",
              "7  2.833      1.0    0.0  \n",
              "8  4.942      3.0    0.0  \n",
              "9  4.143      2.0    0.0  \n",
              "\n",
              "[10 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "e7ZIT0VXMHoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAt8jNSgIUmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "110d6de7-5a50-4c60-f041-68bb29db10d4"
      },
      "cell_type": "code",
      "source": [
        "churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
        "churn_df.shape\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "XsHOLRjlLyZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "00216b1b-2b95-42e8-8c13-b2d67c7a7e21"
      },
      "cell_type": "code",
      "source": [
        "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
        "X[0:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
              "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
              "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
              "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
              "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "O-W7aCXYMInQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39d0dd73-da5e-46f9-e8cd-0e248913e7c9"
      },
      "cell_type": "code",
      "source": [
        "y = np.asarray(churn_df['churn'])\n",
        "y [0:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "AQ9Ps1VBW-cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f8eb3632-652c-419d-fe6a-f1b7109b5b95"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "X[0:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
              "        -0.58477841, -0.85972695],\n",
              "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
              "        -1.14437497, -0.85972695],\n",
              "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
              "        -0.92053635, -0.85972695],\n",
              "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
              "        -0.02518185,  1.16316   ],\n",
              "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
              "         0.53441472, -0.85972695]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "5RDRywJ5XKb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cfd3363b-fb07-4efa-e966-1a74da4fe667"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: (160, 7) (160,)\n",
            "Test set: (40, 7) (40,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WzEot0vcb4_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b71d1acf-9789-4316-f67d-61f20d3b51d2"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
        "LR"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "ICJrkvVNb9Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "569f321a-f9d0-4828-b20d-73b06ff95aa0"
      },
      "cell_type": "code",
      "source": [
        "yhat = LR.predict(X_test)\n",
        "yhat"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "0LMcydPZcNUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "93b1129c-f273-4588-a1ff-692d6bb0ed1b"
      },
      "cell_type": "code",
      "source": [
        "yhat_prob = LR.predict_proba(X_test)\n",
        "yhat_prob"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54132919, 0.45867081],\n",
              "       [0.60593357, 0.39406643],\n",
              "       [0.56277713, 0.43722287],\n",
              "       [0.63432489, 0.36567511],\n",
              "       [0.56431839, 0.43568161],\n",
              "       [0.55386646, 0.44613354],\n",
              "       [0.52237207, 0.47762793],\n",
              "       [0.60514349, 0.39485651],\n",
              "       [0.41069572, 0.58930428],\n",
              "       [0.6333873 , 0.3666127 ],\n",
              "       [0.58068791, 0.41931209],\n",
              "       [0.62768628, 0.37231372],\n",
              "       [0.47559883, 0.52440117],\n",
              "       [0.4267593 , 0.5732407 ],\n",
              "       [0.66172417, 0.33827583],\n",
              "       [0.55092315, 0.44907685],\n",
              "       [0.51749946, 0.48250054],\n",
              "       [0.485743  , 0.514257  ],\n",
              "       [0.49011451, 0.50988549],\n",
              "       [0.52423349, 0.47576651],\n",
              "       [0.61619519, 0.38380481],\n",
              "       [0.52696302, 0.47303698],\n",
              "       [0.63957168, 0.36042832],\n",
              "       [0.52205164, 0.47794836],\n",
              "       [0.50572852, 0.49427148],\n",
              "       [0.70706202, 0.29293798],\n",
              "       [0.55266286, 0.44733714],\n",
              "       [0.52271594, 0.47728406],\n",
              "       [0.51638863, 0.48361137],\n",
              "       [0.71331391, 0.28668609],\n",
              "       [0.67862111, 0.32137889],\n",
              "       [0.50896403, 0.49103597],\n",
              "       [0.42348082, 0.57651918],\n",
              "       [0.71495838, 0.28504162],\n",
              "       [0.59711064, 0.40288936],\n",
              "       [0.63808839, 0.36191161],\n",
              "       [0.39957895, 0.60042105],\n",
              "       [0.52127638, 0.47872362],\n",
              "       [0.65975464, 0.34024536],\n",
              "       [0.5114172 , 0.4885828 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "mxd5cO9DcQeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2b78ccc-2de6-4cb6-a1a7-b3edf1c005d2"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "print(confusion_matrix(y_test, yhat, labels=[1,0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6  9]\n",
            " [ 1 24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fj2VZFAAhsTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "93e29797-ce7d-454d-868a-ba364c4e425a"
      },
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 6  9]\n",
            " [ 1 24]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEmCAYAAAAJAaljAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fea2bba8fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-pjDV7gOlyaV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ". The first row is for customers whose actual churn value in test set is 1. As you can calculate, out of 40 customers, the churn value of 15 of them is 1. And out of these 15, the classifier correctly predicted 6 of them as 1, and 9 of them as 0.\n",
        "\n",
        "It means, for 6 customers, the actual churn value were 1 in test set, and classifier also correctly predicted those as 1. However, while the actual label of 9 customers were 1, the classifier predicted those as 0, which is not very good. We can consider it as error of the model for first row.\n",
        "\n",
        "For  the customers with churn value 0 in the second row. It looks like there were 25 customers whom their churn value were 0.\n",
        "\n",
        "The classifier correctly predicted 24 of them as 0, and one of them wrongly as 1. So, it has done a good job in predicting the customers with churn value 0. A good thing about confusion matrix is that shows the model’s ability to correctly predict or separate the classes. In specific case of binary classifier, such as this example, we can interpret these numbers as the count of true positives, false positives, true negatives, and false negatives."
      ]
    },
    {
      "metadata": {
        "id": "2TLDZgY2mUoC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9bfe3f80-9050-4a11-91ec-ecf499a68f5f"
      },
      "cell_type": "code",
      "source": [
        "print (classification_report(y_test, yhat))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.96      0.83        25\n",
            "        1.0       0.86      0.40      0.55        15\n",
            "\n",
            "avg / total       0.78      0.75      0.72        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8_6r0X2hmx4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a77f94a-ab6b-4929-ba3a-55b540884728"
      },
      "cell_type": "code",
      "source": [
        "#log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1.\n",
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_test, yhat_prob)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6017092478101185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "9i0OG3uFojsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "270384dc-64aa-4610-bf74-68a8e902f48a"
      },
      "cell_type": "code",
      "source": [
        "# Stochastic Average Gradient  SAG\n",
        "\n",
        "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n",
        "yhat_pred = LR2.predict_proba(X_test)\n",
        "print (\"LogLoss: : %.2f\" % log_loss(y_test, yhat_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss: : 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qAsWK9bvpHAP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Log loss is higher when we use Stochastice average gradient as regularization\n"
      ]
    },
    {
      "metadata": {
        "id": "VC2FBf4Win5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f5c660c-8921-4275-de71-297886c2cd68"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#MAE L1 loss function - Should be close to 0\n",
        "from sklearn.metrics import mean_absolute_error  \n",
        "mean_absolute_error(y_test,yhat) #y_target, y_pred"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "98-ExEwmipX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92755655-1165-48dd-a50d-d686d882d901"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# MSE L2 loss - Should be close to 0\n",
        "from sklearn.metrics import mean_squared_error \n",
        "mean_squared_error(y_test,yhat) #y_target, y_pred"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "afIGg-5bkI7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5947c8d9-c912-4394-cb0a-8f9eef51738d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "print (\"Accuracy : \", accuracy_score(y_test,yhat)*100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  75.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}